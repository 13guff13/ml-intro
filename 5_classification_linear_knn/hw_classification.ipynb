{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.75 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, eta=0.001, max_iter=1000, C=1.0, tol=1e-5, random_state=42, zero_init=False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = RandomState(seed=random_state)\n",
    "        self.zero_init = zero_init\n",
    "         \n",
    "    def get_sigmoid(self, x, weights):\n",
    "        \"\"\"Compute the sigmoid value.\"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "    \n",
    "    def get_loss(self, x, weights, y):\n",
    "        \"\"\"Calculate the loss.\"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.classes_ = np.unique(y)\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X]) # a constant feature is included to handle intercept\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features) \n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low=-weight_threshold,\n",
    "                                                     high=weight_threshold, size=num_features) # random weight initialization\n",
    "        for i in range(self.max_iter):\n",
    "            delta = \"<your code>\"\n",
    "            self.weights_ -= self.eta * delta\n",
    "            if \"<your code>\":\n",
    "                break\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "y_train = \"<your code>\"\n",
    "y_test = \"<your code>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(y_pred=clf.predict(X_train), y_true=y_train), \\\n",
    "           metrics.accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter=1, zero_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([ 3.1000e-06,  0.0000e+00,  4.1800e-05,  5.4770e-04,  2.2130e-04,\n",
    "        4.8750e-04,  1.3577e-03,  5.9780e-04,  5.6400e-05, -7.0000e-07,\n",
    "        1.6910e-04,  2.5190e-04, -4.3700e-04,  3.6190e-04,  1.0049e-03,\n",
    "        4.2280e-04,  2.5700e-05,  3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "       -2.6200e-04,  8.7540e-04,  4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "        0.0000e+00, -2.2160e-04, -5.7130e-04,  9.8570e-04,  1.3507e-03,\n",
    "        5.0210e-04, -1.7050e-04, -1.0000e-06,  0.0000e+00, -6.7810e-04,\n",
    "       -1.0515e-03, -4.4500e-05,  3.7160e-04,  4.2100e-04, -8.1800e-05,\n",
    "        0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "        1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "       -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "       -3.9560e-04, -1.7700e-05, -3.0000e-07,  2.6800e-05,  6.3920e-04,\n",
    "        1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min(train_acc, test_acc) > 0.9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.25 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/titanic/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/titanic/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n",
    "\n",
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "Select the best model, load the test set and make the predictions. Submit them to kaggle.\n",
    "\n",
    "**Note**. X points will depend on your kaggle leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.76 \\leq score < 0.78,$$\n",
    "$$ f(score) = 2.0, \\ \\ 0.78 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 3.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
